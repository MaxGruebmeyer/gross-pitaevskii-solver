{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9bd218-5cff-4ae3-bbf5-4a7cffbb2afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from scipy.sparse import diags, kron\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb65af78-17d7-420c-b153-22fad7bcff48",
   "metadata": {},
   "source": [
    "# Gross-Pitaevskii Energy Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5096f3-cbfb-42dd-b5d9-c36ba92882cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_squared(v, h, steps):\n",
    "    # Resize vector to 2D array to calculate x and y gradient\n",
    "    v = v.reshape(steps, steps)\n",
    "    dv_dx = np.gradient(v, h, axis=0)\n",
    "    dv_dy = np.gradient(v, h, axis=1)\n",
    "\n",
    "    # Compute |nabla v|^2\n",
    "    return dv_dx * dv_dx + dv_dy * dv_dy \n",
    "\n",
    "# Calculate the energy of the 2D Gross-Pitaevskii equation depending on\n",
    "# - The potential V\n",
    "# - The repulsion constant beta\n",
    "# - The current vector v (assumes 2D input as just one big vector)\n",
    "# - The step size h (assumes equidistant discretization)\n",
    "# - The number of steps\n",
    "def calculate_energy(v, V, beta, h, steps):\n",
    "    grad_sq = grad_squared(v, h, steps)\n",
    "    h_sq = h * h\n",
    "    v_sq = v * v\n",
    "    \n",
    "    kinetic = np.sum(grad_sq) * h_sq\n",
    "    potential = 2 * np.sum(V * v_sq) * h_sq\n",
    "    interaction = beta * np.sum(v_sq * v_sq) * h_sq\n",
    "\n",
    "    return .25 * (kinetic + potential + interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b803e5c-f7e7-436e-b58a-09a59ac68bba",
   "metadata": {},
   "source": [
    "# The inverse iteration algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6ad35e-0071-4cc2-8ac4-b9cc51ba6416",
   "metadata": {},
   "source": [
    "## General inverse iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5448f529-9b8d-496b-9d01-f7c84245a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs the general inverse iteration algorithm with the following parameters\n",
    "# - A which is a function depending on a vector v\n",
    "# - calc_E which is a function accepting a vector and returning an energy\n",
    "# Returns the following parameters\n",
    "# - A boolean indicating success (True if successful)\n",
    "# - The number of iterations needed (or np.inf if not successful)\n",
    "# - The solution\n",
    "# - An array of residuum values\n",
    "# - An array of energy values\n",
    "# - An array of the differences between u^n and u^{n-1} as norm(u^n - u^{n-1}\n",
    "def inverse_iteration(A, calc_E, dim, max_steps, tol):\n",
    "    start_vec = np.ones(dim)\n",
    "    start_vec /= norm(start_vec)\n",
    "    u_last = start_vec\n",
    "    \n",
    "    iterated_values = np.zeros((max_steps, dim))\n",
    "    energy = np.zeros(max_steps)\n",
    "    \n",
    "    for i in range(0, max_steps):\n",
    "        A_u = A(u_last)\n",
    "        u_cur = spsolve(A_u, u_last)\n",
    "        u_cur /= norm(u_cur)\n",
    "\n",
    "        iterated_values[i] = u_cur\n",
    "        energy[i] = calc_E(u_cur)\n",
    "        \n",
    "        if norm(u_cur - u_last) < tol:\n",
    "            residuum = norm(iterated_values[:i] - u_cur, axis=1)\n",
    "            diffs = norm(iterated_values[:i] - np.insert(iterated_values, 0, start_vec, axis=0)[:i], axis=1)\n",
    "            return (True, i, u_cur, residuum, energy[:i], diffs)\n",
    "\n",
    "        u_last = u_cur\n",
    "\n",
    "    diffs = norm(iterated_values - np.insert(iterated_values, 0, start_vec, axis=0)[:-1], axis=1)\n",
    "    return (False, np.inf, u_cur, np.array([np.inf]), energy, diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6770f5-0ea7-4f80-a79c-241ad90afe63",
   "metadata": {},
   "source": [
    "## Dampened inverse iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a6f757-5733-4322-8154-515a6d39ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_line(tau, u_cur, u_last):\n",
    "    tmp = u_cur.T @ u_last\n",
    "\n",
    "    # Check this to avoid an accidental blow-up\n",
    "    if tmp < 1e-12:\n",
    "        raise Exception(\"Do not want to calculate inverse: Gamma too large!\")\n",
    "    \n",
    "    gamma = 1. / tmp\n",
    "    res = (1. - tau) * u_last + tau * gamma * u_cur\n",
    "\n",
    "    return res / norm(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e796f17d-45df-46e0-b29e-bc7621a0127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs the dampened inverse iteration algorithm with adaptive dampening and turns\n",
    "# off the dampening once norm(u^{n+1} - u^n) < 1e-3\n",
    "# - A which is a function depending on a vector v\n",
    "# - calc_E which is a function accepting a vector and returning an energy\n",
    "# Returns the following parameters\n",
    "# - A boolean indicating success (True if successful)\n",
    "# - The number of iterations needed (or np.inf if not successful)\n",
    "# - The solution\n",
    "# - An array of residuum values\n",
    "# - An array of energy values\n",
    "# - An array of the differences between u^n and u^{n-1} as norm(u^n - u^{n-1}\n",
    "def dampened_inverse_iteration(A, calc_E, dim, max_steps, tol):\n",
    "    damping_stop = 1e-3\n",
    "    start_vec = np.ones(dim)\n",
    "    start_vec /= norm(start_vec)\n",
    "    u_last = start_vec\n",
    "\n",
    "    iterated_values = np.zeros((max_steps, dim))\n",
    "    energy = np.zeros(max_steps)\n",
    "    \n",
    "    damping = True\n",
    "    for i in range(0, max_steps):\n",
    "        A_u = A(u_last)\n",
    "        u_cur = spsolve(A_u, u_last)\n",
    "\n",
    "        if damping:\n",
    "            def objective(tau):\n",
    "                u_tau = compute_line(tau, u_cur, u_last)\n",
    "                return calc_E(u_tau)\n",
    "\n",
    "            opt_tau = minimize_scalar(objective, bounds=(0,2), method='bounded')\n",
    "            if not opt_tau.success:\n",
    "                raise Exception(\"Could not optimize for tau!\")\n",
    "\n",
    "            tau = opt_tau.x\n",
    "            print(f\"Dampening chose optimal tau={tau}.\")\n",
    "\n",
    "            # compute_line is already normalized\n",
    "            u_cur = compute_line(tau, u_cur, u_last)\n",
    "        else:\n",
    "            u_cur /= norm(u_cur)\n",
    "\n",
    "        iterated_values[i] = u_cur\n",
    "        energy[i] = calc_E(u_cur)\n",
    "        \n",
    "        diff = norm(u_cur - u_last)\n",
    "        if diff < tol:\n",
    "            # At least one more run to make sure diff < tol isn't because of small damping steps\n",
    "            if damping:\n",
    "                print(f\"Turned off damping after {i + 1} steps because of diff < tol!\")\n",
    "                damping = False\n",
    "            else:\n",
    "                residuum = norm(iterated_values[:i] - u_cur, axis=1)\n",
    "                diffs = norm(iterated_values[:i] - np.insert(iterated_values, 0, start_vec, axis=0)[:i], axis=1)\n",
    "                return (True, i, u_cur, residuum, energy[:i], diffs)\n",
    "\n",
    "        if damping and diff < damping_stop:\n",
    "            print(f\"Turned off damping after {i + 1} steps!\")\n",
    "            damping = False\n",
    "        \n",
    "        u_last = u_cur\n",
    "\n",
    "    diffs = norm(iterated_values - np.insert(iterated_values, 0, start_vec, axis=0)[:-1], axis=1)\n",
    "    return (False, np.inf, u_cur, np.array([np.inf]), energy, diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77073fd-4e7a-4153-9f74-1e1dd0dd3671",
   "metadata": {},
   "source": [
    "## Inverse Iteration with Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d769f00-3fe3-4075-b6a2-fa81e57d022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs the inverse iteration algorithm with dynamic shifting (rayleigh-quotient of last iterated) and the following parameters\n",
    "# - A which is a function depending on a vector v\n",
    "# - calc_E which is a function accepting a vector and returning an energy\n",
    "# Returns the following parameters\n",
    "# - A boolean indicating success (True if successful)\n",
    "# - The number of iterations needed (or np.inf if not successful)\n",
    "# - The solution\n",
    "# - An array of residuum values\n",
    "# - An array of energy values\n",
    "# - An array of the differences between u^n and u^{n-1} as norm(u^n - u^{n-1}\n",
    "def shifted_inverse_iteration(A, calc_E, dim, max_steps, tol):\n",
    "    ones = np.ones(dim)\n",
    "    start_vec = ones / norm(ones)\n",
    "    u_last = start_vec\n",
    "    \n",
    "    iterated_values = np.zeros((max_steps, dim))\n",
    "    energy = np.zeros(max_steps)\n",
    "    \n",
    "    for i in range(0, max_steps):\n",
    "        A_u = A(u_last)\n",
    "        shift = u_last.T @ A_u @ u_last / (u_last.T @ u_last)\n",
    "        \n",
    "        u_cur = spsolve(A_u - diags(shift * ones), u_last)\n",
    "        u_cur /= norm(u_cur)\n",
    "\n",
    "        iterated_values[i] = u_cur\n",
    "        energy[i] = calc_E(u_cur)\n",
    "        \n",
    "        if norm(u_cur - u_last) < tol:\n",
    "            residuum = norm(iterated_values[:i] - u_cur, axis=1)\n",
    "            diffs = norm(iterated_values[:i] - np.insert(iterated_values, 0, start_vec, axis=0)[:i], axis=1)\n",
    "            return (True, i, u_cur, residuum, energy[:i], diffs)\n",
    "\n",
    "        u_last = u_cur\n",
    "\n",
    "    diffs = norm(iterated_values - np.insert(iterated_values, 0, start_vec, axis=0)[:-1], axis=1)\n",
    "    return (False, np.inf, u_cur, np.array([np.inf]), energy, diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc60003c-2da6-49be-8081-a4c47ae4a08a",
   "metadata": {},
   "source": [
    "# Solving the Gross-Pitaevskii Eigenvalue Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf6d55-c17c-49ae-afc8-bbee933668b0",
   "metadata": {},
   "source": [
    "## Precomputed Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1c122-4390-4ffc-b719-2458cf28151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the 1D Laplace of size (dim_sqrt, dim_sqrt) scaled by h_inv_sq = 1/h^2\n",
    "def get_D2(dim_sqrt, h_inv_sq):\n",
    "    diagonals = [-np.ones(dim_sqrt-1), 2*np.ones(dim_sqrt), -np.ones(dim_sqrt-1)]\n",
    "    offsets = [-1, 0, 1]\n",
    "    return 1. * h_inv_sq * diags(diagonals, offsets, format='csr')\n",
    "\n",
    "# Returns the 2D Laplace of size (dim_sqrt * dim_sqrt, dim_sqrt * dim_sqrt)\n",
    "# as a sparse CSR matrix\n",
    "def get_L(dim_sqrt, h_inv_sq):\n",
    "    D_2 = get_D2(dim_sqrt, h_inv_sq)\n",
    "    I = diags(np.ones(dim_sqrt), 0, format='csr')\n",
    "    return kron(D_2, I) + kron(I, D_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf8eec3-8a7e-464a-a034-2040847df5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the harmonic potential M by discretizing\n",
    "#  [-bound, bound]^2 in a (steps, steps) grid\n",
    "def get_M(bound, steps):\n",
    "    x = np.linspace(-bound, bound, steps)\n",
    "    y = np.linspace(-bound, bound, steps)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    f = lambda x, y: (x * x + y * y) * .5\n",
    "    Z = f(X, Y)\n",
    "    return diags(Z.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169f4087-f9f3-4fe9-9e1e-50c3261d9b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns L_M, e.g. the constant part of the GPE (Laplace + Potential)\n",
    "def get_L_M(bound, steps, h_inv_sq):\n",
    "    # Steps = dim_sqrt since we discretize in a (steps, steps) field\n",
    "    L_N = get_L(steps, h_inv_sq)\n",
    "    M_V = get_M(bound, steps)\n",
    "\n",
    "    return L_N + M_V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f0c442-6499-487a-9a48-f77a749ec3be",
   "metadata": {},
   "source": [
    "## Dynamic Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6342f92d-df62-46f7-97dc-9c54475eb7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the nonlinearity, e.g. the particle repulsion, depending on\n",
    "# - v, the current state\n",
    "# - the repulsion constant beta (nonlinearity parameter)\n",
    "# - h_inv_sq = 1/h^2 where h is the step size\n",
    "def get_A_squiddle(v, beta, h_inv_sq):\n",
    "    # Calculate diag(|v|)^2 = diag(|v|^2) = diag(v^2)\n",
    "    D = diags(np.multiply(v, v))\n",
    "    return h_inv_sq * beta * D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eaa5f9-f631-4e57-86cc-122d9ea7e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates A(v) where\n",
    "# - L_M is the precomputed part of the problem\n",
    "# - v is the current vector\n",
    "# - beta is a nonlinearity parameter (repulsion constant)\n",
    "# - h_inv_sq = 1/h^2 where h is the step size\n",
    "def A_v(L_M, v, beta, h_inv_sq):\n",
    "    return L_M + get_A_squiddle(v, beta, h_inv_sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afad01-4d18-4787-8ce6-ad0e925de38c",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4b7fa0-051b-4170-81b0-8afd915c40a3",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc16c39-6383-458a-9a7a-30e5d799dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 200\n",
    "tol = 1e-8\n",
    "bound = 8.\n",
    "steps = 200\n",
    "betas = np.array([1e-1, 1e0, 1e+1, 1e+2, 1e+3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352bb2c9-e672-4fc2-956d-87da6f34c1f1",
   "metadata": {},
   "source": [
    "## Precomputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18459fe-6633-4b00-a767-f8e68d90d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 2 * bound / steps\n",
    "h_inv_sq = 1 / (h * h)\n",
    "L_M = get_L_M(bound, steps, h_inv_sq)\n",
    "\n",
    "# Potential V. Needed seperately for dampening\n",
    "V = get_M(bound, steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33df2608-1ab6-4853-83a2-3c24ebf2ab7f",
   "metadata": {},
   "source": [
    "## Helper methods for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac548f5-0fa3-4b79-9d27-64033cf1e1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(axes, taken_steps, residuum, energy, diffs, beta, color, label=None):\n",
    "    pt_range = np.arange(taken_steps)\n",
    "    # Only add label once - we want the legend once for the whole figure\n",
    "    if label == None:\n",
    "        axes[0,0].plot(pt_range, residuum[:taken_steps], label=f\"beta={beta}\", c=color, marker='o')\n",
    "    else:\n",
    "        axes[0,0].plot(pt_range, residuum[:taken_steps], label=label, c=color, marker='o')\n",
    "\n",
    "    axes[0,1].plot(pt_range, diffs[:taken_steps], c=color, marker='o')\n",
    "    axes[1,0].plot(pt_range, energy[:taken_steps], c=color, marker='o')\n",
    "\n",
    "    pt_range = pt_range[:-1]\n",
    "    energy_diff = energy[:taken_steps-1] - energy[1:taken_steps]\n",
    "    axes[1,1].plot(pt_range, np.full_like(pt_range, 0), color='gray', linestyle='-.')\n",
    "    axes[1,1].plot(pt_range, energy_diff, c = color, marker='o')\n",
    "\n",
    "def plot_failed_result(axes, taken_steps, energy, diffs, beta, color):\n",
    "    pt_range = np.arange(taken_steps)\n",
    "    # Do not plot residuum - we don't have a result!\n",
    "    \n",
    "    # Only add label once - we want the legend once for the whole figure\n",
    "    axes[0,1].plot(pt_range, diffs[:taken_steps], label=f\"beta={beta}\", c=color, marker='o')\n",
    "    axes[1,0].plot(pt_range, energy[:taken_steps], c=color, marker='o')\n",
    "\n",
    "    pt_range = pt_range[:-1]\n",
    "    energy_diff = energy[:taken_steps-1] - energy[1:taken_steps]\n",
    "    axes[1,1].plot(pt_range, np.full_like(pt_range, 0), color='gray', linestyle='-.')\n",
    "    axes[1,1].plot(pt_range, energy_diff, c = color, marker='o')\n",
    "\n",
    "def config_result_plot(fig, axes):\n",
    "    axes[0,0].set_yscale('log')\n",
    "    axes[0,0].set_xscale('log')\n",
    "    axes[0,0].set_ylabel('Residuum')\n",
    "    axes[0,0].set_xlabel('Steps')\n",
    "    \n",
    "    axes[0,1].set_yscale('log')\n",
    "    axes[0,1].set_xscale('log')\n",
    "    axes[0,1].set_ylabel('Differences $\\Vert u^n - u^{n-1} \\Vert$')\n",
    "    axes[0,1].set_xlabel('Steps')\n",
    "    \n",
    "    axes[1,0].set_yscale('linear')\n",
    "    axes[1,0].set_xscale('log')\n",
    "    axes[1,0].set_ylabel('Energy $E(u^n)$')\n",
    "    axes[1,0].set_xlabel('Steps')\n",
    "    \n",
    "    axes[1,1].set_yscale('linear')\n",
    "    axes[1,1].set_xscale('log')\n",
    "    axes[1,1].set_ylabel('Energy diff $E(u^{n-1}) - E(u^n)$')\n",
    "    axes[1,1].set_xlabel('Steps')\n",
    "    \n",
    "    fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdc3de3-d2dd-4f9e-92a8-c09d1bf20ca9",
   "metadata": {},
   "source": [
    "## Helper function to run the inverse iteration algorithms and remove duplicate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a016dd-f5a0-4329-9dbd-bfa2b3d57ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs one of the inverse iteration algorithms (e.g. normal, shifted, dampenened) and graphs it.\n",
    "# The graph will be saved to file_name\n",
    "# Algo is a function taking parameters\n",
    "# - A (lambda function taking vector and returning a matrix)\n",
    "# - calc_E (a lambda function to calculate the energy functional depending on a vector)\n",
    "# - The dimension of the problem\n",
    "# - A maximum number of steps after which to abort\n",
    "# - A tolerance after which to abort\n",
    "def run_algo(algo, file_name):\n",
    "    colors = [\"darkgreen\", \"gold\", \"orange\", \"red\", \"darkred\"]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    for i in range(betas.shape[0]):\n",
    "        beta = betas[i]\n",
    "        A = lambda v: A_v(L_M, v, beta, h_inv_sq)\n",
    "        calc_E = lambda v: calculate_energy(v, V, beta, h, steps)\n",
    "        \n",
    "        print(f\"Starting with bound={bound}, steps={steps} and beta={beta}\")\n",
    "    \n",
    "        (success, taken_steps, last, residuum, energy, diffs) = algo(A, calc_E, steps * steps, max_steps, tol)\n",
    "        if success:\n",
    "            eigenval = last.T @ A(last) @ last / (last.T @ last)\n",
    "            print(f\"Successful iteration with convergence in {taken_steps + 1} steps towards eigenvalue {round(eigenval, 2)}\")\n",
    "            plot_result(axes, taken_steps, residuum, energy, diffs, beta, colors[i])        \n",
    "        else:\n",
    "            print(f\"Iteration failed after {max_steps} steps!\")\n",
    "            plot_failed_result(axes, max_steps, energy, diffs, beta, 'black')        \n",
    "    \n",
    "    config_result_plot(fig, axes)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_name, dpi=300)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3700152a-a410-4bb8-adb3-15e8ded8bab4",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de0d896-5240-4d42-a324-d4990bfaee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_algo(inverse_iteration, 'gpe-inverse-iteration.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20651b57-5824-4677-8bbe-6152d23fb2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_algo(dampened_inverse_iteration, 'gpe-inverse-iteration-dampened.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9510bcff-98bf-4638-8221-0c6b96bf548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_algo(shifted_inverse_iteration, 'gpe-inverse-iteration-shifted.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e5f96-bd32-471f-93f6-a0cc594c23c9",
   "metadata": {},
   "source": [
    "## Comparision dampened - undampened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc3cd2-2d74-4d78-9e34-a74ed8c611b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_colors = [\"darkgreen\", \"forestgreen\", \"green\", \"limegreen\", \"springgreen\"]\n",
    "u_colors = [\"gold\", \"orange\", \"darkorange\", \"red\", \"darkred\"]\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 12))\n",
    "\n",
    "# A bit hacky, but it allows for reusing existing methods\n",
    "u_axes = axes[[0,2],:]\n",
    "d_axes = axes[1:,:]\n",
    "for i in range(betas.shape[0]):\n",
    "    beta = betas[i]\n",
    "    A = lambda v: A_v(L_M, v, beta, h_inv_sq)\n",
    "    calc_E = lambda v: calculate_energy(v, V, beta, h, steps)\n",
    "    \n",
    "    print(f\"Starting with bound={bound}, steps={steps} and beta={beta}\")\n",
    "\n",
    "    (u_success, u_taken_steps, u_last, u_residuum, u_energy, u_diffs) = inverse_iteration(A, calc_E, steps * steps, max_steps, tol)\n",
    "    (d_success, d_taken_steps, d_last, d_residuum, d_energy, d_diffs) = dampened_inverse_iteration(A, calc_E, steps * steps, max_steps, tol)\n",
    "\n",
    "    if u_success and d_success:\n",
    "        print(f\"Normal iteration converged after {u_taken_steps + 1} while dampened version took {d_taken_steps + 1}!\")\n",
    "        print(f\"Diff normal/damped: {norm(u_last - d_last)}\")\n",
    "        plot_result(u_axes, u_taken_steps, u_residuum, u_energy, u_diffs, beta, u_colors[i], label=f\"beta={beta} (normal)\")\n",
    "        plot_result(d_axes, d_taken_steps, d_residuum, d_energy, d_diffs, beta, d_colors[i], label=f\"beta={beta} (dampened)\")\n",
    "    else:\n",
    "        print(f\"Dampened (success={d_success}) or normal (success={u_success}) inverse iteration failed!\")\n",
    "\n",
    "config_result_plot(fig, u_axes)\n",
    "config_result_plot(fig, d_axes)\n",
    "plt.tight_layout()\n",
    "plt.savefig('gpe-inverse-iteration-comparision.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7529e9c3-a1a8-4b9a-8f6a-c9b482c385c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
